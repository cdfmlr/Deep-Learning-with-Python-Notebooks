{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Python\n",
    "\n",
    "## 8.5 Introduction to generative adversarial networks\n",
    "\n",
    "> ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œç®€ä»‹\n",
    "\n",
    "GANï¼Œä¸­æ–‡æ˜¯~~æ·¦~~ï¼Œé”™äº†ï¼Œç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ(Generative Adversarial Network)ã€‚å’Œ VAE ä¸€æ ·ï¼Œæ˜¯ç”¨æ¥å­¦ä¹ å›¾åƒçš„æ½œåœ¨ç©ºé—´çš„ã€‚è¿™ä¸œè¥¿å¯ä»¥ä½¿ç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒâ€œåœ¨ç»Ÿè®¡ä¸Šâ€åˆ«æ— äºŒè‡´ï¼Œè¯´äººè¯å°±æ˜¯ï¼Œç”Ÿæˆçš„å›¾åƒç›¸å½“é€¼çœŸã€‚ä½†ä¸ VAE ä¸åŒï¼ŒGAN çš„æ½œåœ¨ç©ºé—´æ— æ³•ä¿è¯å…·æœ‰æœ‰æ„ä¹‰çš„ç»“æ„ï¼Œå¹¶ä¸”æ˜¯ä¸è¿ç»­çš„ã€‚\n",
    "\n",
    "GAN ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š\n",
    "\n",
    "- ç”Ÿæˆå™¨ç½‘ç»œ(generator network)ï¼šè¾“å…¥ä¸€ä¸ªéšæœºå‘é‡(æ½œåœ¨ç©ºé—´ä¸­çš„ä¸€ä¸ªéšæœºç‚¹)ï¼Œå¹¶å°†å…¶è§£ç ä¸ºå›¾åƒã€‚\n",
    "- åˆ¤åˆ«å™¨ç½‘ç»œ(discriminator network)ï¼šè¾“å…¥ä¸€å¼ å›¾åƒ(çœŸå®çš„æˆ–ç”Ÿæˆå™¨ç”»çš„)ï¼Œé¢„æµ‹è¯¥å›¾åƒæ˜¯çœŸå®çš„è¿˜æ˜¯ç”±ç”Ÿæˆå™¨ç½‘ç»œåˆ›å»ºçš„ã€‚ï¼ˆåˆ¤åˆ«å™¨ç½‘ç»œä¹Ÿå«ã€Œå¯¹æ‰‹ã€ï¼Œadversaryï¼‰\n",
    "\n",
    "è®­ç»ƒ GAN çš„ç›®çš„æ˜¯ä½¿ã€Œç”Ÿæˆå™¨ç½‘ç»œã€èƒ½å¤Ÿæ¬ºéª—ã€Œåˆ¤åˆ«å™¨ç½‘ç»œã€ã€‚\n",
    "\n",
    "ç›´è§‚ç†è§£ GAN æ˜¯ä¸€ä¸ªå¾ˆåŠ±å¿—çš„æ•…äº‹ï¼šå°±æ˜¯è¯´æœ‰ä¸¤ä¸ªäººï¼Œä¸€ä¸ªä¼ªé€ è€…ï¼Œä¸€ä¸ªé‰´å®šå¸ˆã€‚ä¼ªé€ è€…ä»¿é€ å¤§å¸ˆçš„ç”»ï¼Œç„¶åæŠŠè‡ªå·±çš„ä»¿åˆ¶å“æ··åœ¨çœŸè¿¹é‡Œäº¤ç»™é‰´å®šå¸ˆé‰´å®šï¼Œé‰´å®šå¸ˆè¯„ä¼°æ¯ä¸€å¹…ç”»çš„çœŸä¼ªï¼Œä¸€æ ·çœ‹ç©¿äº†å“ªäº›æ˜¯ä¼ªé€ çš„ã€‚å¥½å¿ƒçš„é‰´å®šå¸ˆåé¦ˆäº†ä¼ªé€ è€…ï¼Œå‘Šè¯‰ä»–çœŸè¿¹æœ‰å“ªäº›ç‰¹å¾ã€‚ä¼ªé€ è€…æ ¹æ®é‰´å®šå¸ˆçš„æ„è§ï¼Œä¸€æ­¥æ­¥æå‡è‡ªå·±çš„ä»¿é€ èƒ½åŠ›ã€‚ä¸¤äººä¸åŒå…¶çƒ¦åœ°é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œä¼ªé€ è€…å˜å¾—è¶Šæ¥è¶Šæ“…é•¿å¤åˆ¶å¤§å¸ˆçš„ç”»ï¼Œé‰´å®šå¸ˆä¹Ÿè¶Šæ¥è¶Šæ“…é•¿æ‰¾å‡ºå‡ç”»ã€‚åˆ°æœ€åï¼Œä¼ªé€ è€…é€ å‡ºäº†ä¸€æ‰¹é‰´å®šå¸ˆä¹Ÿæ— å¯æŒ‘å‰”çš„â€œä»¿åˆ¶æ­£å“â€ã€‚\n",
    "\n",
    "![ç”Ÿæˆå™¨å°†éšæœºæ½œåœ¨å‘é‡è½¬æ¢æˆå›¾åƒï¼Œåˆ¤åˆ«å™¨è¯•å›¾åˆ†è¾¨çœŸå®å›¾åƒä¸ç”Ÿæˆå›¾åƒã€‚ç”Ÿæˆå™¨çš„è®­ç»ƒæ˜¯ä¸ºäº†æ¬ºéª—åˆ¤åˆ«å™¨](https://tva1.sinaimg.cn/large/007S8ZIlgy1ghva0rve82j31ec0tcthm.jpg)\n",
    "\n",
    "GAN çš„è®­ç»ƒæ–¹å¼å¾ˆç‰¹æ®Šï¼Œå®ƒçš„ä¼˜åŒ–æœ€å°å€¼æ˜¯ä¸å›ºå®šçš„ã€‚æˆ‘ä»¬é€šå¸¸çš„ã€Œæ¢¯åº¦ä¸‹é™ã€æ˜¯æ²¿ç€é™æ€çš„æŸå¤±åœ°å½¢æ»šä¸‹å±±ï¼Œä½† GAN è®­ç»ƒæ—¶æ¯ä¸‹å±±ä¸€æ­¥éƒ½ä¼šå¯¹æ•´ä¸ªåœ°å½¢é€ æˆæ”¹å˜ã€‚å®ƒæ˜¯ä¸€ä¸ªåŠ¨æ€ç³»ç»Ÿï¼Œå…¶æœ€ä¼˜åŒ–è¿‡ç¨‹æ˜¯ä¸¤è‚¡åŠ›é‡ä¹‹é—´çš„å¹³è¡¡ã€‚æ‰€ä»¥ï¼ŒGAN å¾ˆéš¾è®­ç»ƒã€‚æƒ³è¦è®© GAN æ­£å¸¸è¿è¡Œï¼Œéœ€è¦è¿›è¡Œå¤§é‡çš„æ¨¡å‹æ„å»ºã€è¶…å‚æ•°è°ƒèŠ‚å·¥ä½œã€‚\n",
    "\n",
    "### æ·±åº¦å·ç§¯ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ\n",
    "\n",
    "æˆ‘ä»¬æ¥å°è¯•ç”¨ Keras å®ç°æœ€æœ€æœ€ç®€å•çš„ GANã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¼šåšä¸€ä¸ª**æ·±åº¦å·ç§¯ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ**ï¼ˆdeep convolutional GANï¼ŒDCGANï¼‰ï¼Œè¿™ç§ä¸œè¥¿çš„ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨éƒ½æ˜¯æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†ç”¨ CIFAR10 æ•°æ®é›†ä¸­â€œfrogâ€ç±»åˆ«çš„å›¾åƒè®­ç»ƒ DCGANã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å« 50000 å¼  32Ã—32 çš„ RGB å›¾åƒï¼Œè¿™äº›å›¾åƒå±äº 10 ä¸ªç±»åˆ«(æ¯ä¸ªç±»åˆ« 5000 å¼ å›¾åƒ)ã€‚\n",
    "\n",
    "#### å®ç°æµç¨‹\n",
    "\n",
    "1. `generator` ç½‘ç»œå°†å½¢çŠ¶ä¸º `(latent_dim,)` çš„å‘é‡æ˜ å°„åˆ°å½¢çŠ¶ä¸º `(32, 32, 3)` çš„å›¾åƒã€‚\n",
    "2. `discriminator` ç½‘ç»œå°†å½¢çŠ¶ä¸º `(32, 32, 3)` çš„å›¾åƒæ˜ å°„åˆ°ä¸€ä¸ªäºŒè¿›åˆ¶å¾—åˆ†(a binary score)ï¼Œç”¨äºè¯„ä¼°å›¾åƒä¸ºçœŸçš„æ¦‚ç‡ã€‚\n",
    "3. `gan` ç½‘ç»œå°† `generator` å’Œ `discriminator` è¿æ¥åœ¨ä¸€èµ·: `gan(x) = discriminator(generator(x))`ã€‚è¿™ä¸ªç½‘ç»œæ˜¯å°†æ½œåœ¨å‘é‡æ˜ å°„åˆ°åˆ¤åˆ«å™¨çš„è¯„ä¼°ç»“æœã€‚\n",
    "4. ä½¿ç”¨å¸¦æœ‰ `\"real\"` æˆ– `\"fake\"` æ ‡ç­¾çš„çœŸå‡å›¾åƒæ ·æœ¬æ¥è®­ç»ƒåˆ¤åˆ«å™¨ï¼Œç”¨å¸¸è§„è®­ç»ƒæ™®é€šçš„å›¾åƒåˆ†ç±»æ¨¡å‹çš„æ–¹æ³•ã€‚\n",
    "5. ä¸ºäº†è®­ç»ƒç”Ÿæˆå™¨ï¼Œä½¿ç”¨ `gan` æ¨¡å‹çš„æŸå¤±ç›¸å¯¹äºç”Ÿæˆå™¨æƒé‡çš„æ¢¯åº¦ã€‚åœ¨æ¯ä¸€æ­¥éƒ½è¦å‘ã€Œè®©åˆ¤åˆ«å™¨æ›´æœ‰å¯èƒ½å°†ç”Ÿæˆå™¨è§£ç çš„å›¾åƒåˆ’åˆ†ä¸ºâ€œçœŸâ€ã€ç§»åŠ¨ç”Ÿæˆå™¨çš„æƒé‡ï¼Œå³è®­ç»ƒç”Ÿæˆå™¨æ¥æ¬ºéª—åˆ¤åˆ«å™¨ã€‚\n",
    "\n",
    "#### å®ç”¨æŠ€å·§\n",
    "\n",
    "è®­ç»ƒå’Œè°ƒèŠ‚ GAN çš„è¿‡ç¨‹éå¸¸å›°éš¾ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦è®°ä½ä¸€äº›å‰äººæ€»ç»“å‡ºçš„å®ç”¨æŠ€å·§ã€‚è¿™äº›æŠ€å·§ä¸€èˆ¬å¾ˆæœ‰ç”¨ï¼Œä½†å¹¶ä¸èƒ½é€‚ç”¨äºæ‰€æœ‰æƒ…å†µã€‚è¿™äº›ä¸œè¥¿éƒ½æ²¡æœ‰ç†è®ºä¾æ®ï¼Œéƒ½æ˜¯ç„å­¦ï¼Œæ‰€ä»¥ä¸è§£é‡Šç›´æ¥å†™ç»“è®ºï¼š\n",
    "\n",
    "- ä½¿ç”¨ tanh ä½œä¸ºç”Ÿæˆå™¨æœ€åä¸€å±‚çš„æ¿€æ´»ï¼Œè€Œä¸ç”¨ sigmoidã€‚\n",
    "- ä½¿ç”¨æ­£æ€åˆ†å¸ƒ(é«˜æ–¯åˆ†å¸ƒ)å¯¹æ½œåœ¨ç©ºé—´ä¸­çš„ç‚¹è¿›è¡Œé‡‡æ ·ï¼Œè€Œä¸ç”¨å‡åŒ€åˆ†å¸ƒã€‚\n",
    "- éšæœºæ€§èƒ½å¤Ÿæé«˜ç¨³å¥æ€§ã€‚GAN è®­ç»ƒæ—¶å¯èƒ½ä»¥å„ç§æ–¹å¼â€œå¡ä½â€(è¾¾åˆ°é”™è¯¯çš„åŠ¨æ€å¹³è¡¡)ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥éšæœºæ€§æœ‰åŠ©äºé˜²æ­¢å‡ºç°è¿™ç§æƒ…å†µï¼Œå¼•å…¥éšæœºæ€§çš„æ–¹å¼æœ‰ä¸¤ç§ï¼š\n",
    "    1. åœ¨åˆ¤åˆ«å™¨ä¸­ä½¿ç”¨ dropout;\n",
    "    2. å‘åˆ¤åˆ«å™¨çš„æ ‡ç­¾æ·»åŠ éšæœºå™ªå£°;\n",
    "- ç¨€ç–çš„æ¢¯åº¦ä¼šå¦¨ç¢ GAN çš„è®­ç»ƒã€‚ã€Œæœ€å¤§æ± åŒ–è¿ç®—ã€å’Œ ã€ŒReLU æ¿€æ´»ã€å¯èƒ½å¯¼è‡´æ¢¯åº¦ç¨€ç–ï¼Œæ‰€ä»¥æ¨èï¼š\n",
    "    1. ä½¿ç”¨ã€Œæ­¥è¿›å·ç§¯ã€ä»£æ›¿ã€Œæœ€å¤§æ± åŒ–ã€æ¥è¿›è¡Œä¸‹é‡‡æ ·;\n",
    "    2. ä½¿ç”¨ LeakyReLU å±‚æ¥ä»£æ›¿ ReLU æ¿€æ´»;\n",
    "- åœ¨ç”Ÿæˆçš„å›¾åƒä¸­ï¼Œå¸¸ä¼šè§åˆ°æ£‹ç›˜çŠ¶ä¼ªå½±ï¼Œè¿™æ˜¯ç”±äºç”Ÿæˆå™¨ä¸­åƒç´ ç©ºé—´è¦†ç›–ä¸å‡åŒ€ã€‚è§£å†³è¿™ä¸ªé—®é¢˜çš„åŠæ³•æ˜¯ï¼šæ¯å½“åœ¨ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸­éƒ½ä½¿ç”¨æ­¥è¿› Conv2DTranpose æˆ– Conv2D æ—¶ï¼Œå†…æ ¸å¤§å°è¦èƒ½å¤Ÿè¢«æ­¥å¹…æ•´é™¤ã€‚\n",
    "\n",
    "\n",
    "\n",
    "ç”±äºæ­¥å¹…å¤§å°å’Œå†…æ ¸å¤§å°ä¸åŒ¹é…è€Œå¯¼è‡´çš„æ£‹ç›˜çŠ¶ä¼ªå½±ç¤ºä¾‹å›¾:\n",
    "\n",
    "![ç”±äºæ­¥å¹…å¤§å°å’Œå†…æ ¸å¤§å°ä¸åŒ¹é…è€Œå¯¼è‡´çš„æ£‹ç›˜çŠ¶ä¼ªå½±](https://tva1.sinaimg.cn/large/007S8ZIlgy1ghvayd7ipwj31560ggazl.jpg)\n",
    "\n",
    "#### ç”Ÿæˆå™¨çš„å®ç°\n",
    "\n",
    "å¼€å§‹æ„å»ºå¹´è½»äººçš„ç¬¬ä¸€ä¸ª GAN äº†ï¼ï¼\n",
    "\n",
    "é¦–å…ˆå¼€å‘ generator æ¨¡å‹ï¼šå°†æ¥è‡ªæ½œåœ¨ç©ºé—´çš„å‘é‡è½¬æ¢ä¸ºä¸€å¼ å€™é€‰å›¾åƒã€‚\n",
    "\n",
    "ä¸ºäº†é¿å…è®­ç»ƒæ—¶â€œå¡ä½â€ï¼Œåœ¨åˆ¤åˆ«å™¨å’Œç”Ÿæˆå™¨ä¸­éƒ½ä½¿ç”¨ dropoutã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GAN ç”Ÿæˆå™¨ç½‘ç»œ\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "# å°†è¾“å…¥è½¬æ¢ä¸ºå¤§å°ä¸º 16Ã—16 çš„ 128 ä¸ªé€šé“çš„ç‰¹å¾å›¾\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# ä¸Šé‡‡æ ·ä¸º 32Ã—32\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# ç”Ÿæˆå¤§å°ä¸º 32Ã—32 çš„ç‰¹å¾å›¾(CIFAR10 å›¾åƒçš„å½¢çŠ¶)\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### åˆ¤åˆ«å™¨çš„å®ç°\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œå¼€å‘ discriminator æ¨¡å‹ï¼Œè¾“å…¥ä¸€å¼ å›¾åƒ(çœŸå®çš„æˆ–åˆæˆçš„)ï¼Œå°†å…¶åˆ’åˆ†ä¸ºã€ŒçœŸã€ï¼ˆæ¥è‡ªè®­ç»ƒé›†çš„çœŸå®å›¾åƒï¼‰æˆ–ã€Œå‡ã€ï¼ˆç”Ÿæˆå™¨ç”»çš„å›¾åƒï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GAN åˆ¤åˆ«å™¨ç½‘ç»œ\n",
    "\n",
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "    lr=0.0008,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "                      loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å¯¹æŠ—ç½‘ç»œ\n",
    "\n",
    "æœ€åï¼Œè®¾ç½® GANï¼Œå°†ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨è¿æ¥åœ¨ä¸€èµ·ï¼Œå°†æ½œåœ¨ç©ºé—´çš„ç‚¹è½¬æ¢ä¸ºä¸€ä¸ªçœŸæˆ–å‡çš„åˆ†ç±»åˆ¤æ–­ã€‚\n",
    "\n",
    "è¿™ä¸ªæ¨¡å‹è®­ç»ƒæ—¶ï¼Œéœ€è¦å°†ã€Œåˆ¤åˆ«å™¨ã€å†»ç»“(ä½¿ä¹‹ä¸å¯è¢«è®­ç»ƒ)ï¼Œåªè®©ã€Œç”Ÿæˆå™¨ã€å‘ã€Œæé«˜æ¬ºéª—åˆ¤åˆ«å™¨çš„èƒ½åŠ›ã€çš„æ–¹å‘ç§»åŠ¨ã€‚\n",
    "\n",
    "è®­ç»ƒ gan æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„å…¨éƒ¨éƒ½æ˜¯â€œçœŸå®å›¾åƒâ€çš„æ ‡ç­¾ï¼Œæ‰€ä»¥å¦‚æœåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥å¯¹ã€Œåˆ¤åˆ«å™¨ã€çš„æƒé‡è¿›è¡Œæ›´æ–°ï¼Œè®­ç»ƒä¼šä½¿å¾—åˆ¤åˆ«å™¨å§‹ç»ˆé¢„æµ‹â€œçœŸâ€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æŠ—ç½‘ç»œ\n",
    "\n",
    "discriminator.trainable = False    # è¿™ä¸ªåªä¼šä½œç”¨äº gan\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(\n",
    "    lr=0.0004,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer,\n",
    "            loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### è®­ç»ƒ DCGAN\n",
    "\n",
    "è®­ç»ƒå¾ªç¯çš„æµç¨‹å¦‚ä¸‹:\n",
    "\n",
    "1. ä»æ½œåœ¨ç©ºé—´ä¸­æŠ½å–éšæœºçš„ç‚¹(éšæœºå™ªå£°)ã€‚\n",
    "2. æŠŠè¿™ä¸ªéšæœºå™ªå£°ç»™ generator ç”Ÿæˆå›¾åƒã€‚\n",
    "3. å°†ç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒæ··åˆã€‚\n",
    "4. ä½¿ç”¨è¿™äº›æ··åˆåçš„å›¾åƒä»¥åŠç›¸åº”çš„æ ‡ç­¾(çœŸå®å›¾åƒä¸ºâ€œçœŸâ€ï¼Œç”Ÿæˆå›¾åƒä¸ºâ€œå‡â€)æ¥è®­ç»ƒ discriminatorã€‚\n",
    "5. åœ¨æ½œåœ¨ç©ºé—´ä¸­éšæœºæŠ½å–æ–°çš„ç‚¹ã€‚\n",
    "6. ä½¿ç”¨è¿™äº›éšæœºå‘é‡ä»¥åŠå…¨éƒ¨æ˜¯ã€ŒçœŸå®å›¾åƒã€çš„æ ‡ç­¾æ¥è®­ç»ƒganã€‚\n",
    "\n",
    "å…·ä½“çš„ä»£ç å®ç°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: discriminator loss: 0.6944685578346252, adversarial loss: 0.7566524744033813\n",
      "step 50: discriminator loss: 0.6997207999229431, adversarial loss: 0.7283448576927185\n",
      "step 100: discriminator loss: 0.6917451024055481, adversarial loss: 0.7818207144737244\n",
      "step 150: discriminator loss: 0.7006672620773315, adversarial loss: 0.77472984790802\n",
      "step 200: discriminator loss: 0.6959202885627747, adversarial loss: 0.7540444731712341\n",
      "step 250: discriminator loss: 0.6907225847244263, adversarial loss: 0.7319836020469666\n",
      "step 300: discriminator loss: 0.6964272856712341, adversarial loss: 0.795426070690155\n",
      "step 350: discriminator loss: 0.7021819949150085, adversarial loss: 0.7412662506103516\n",
      "step 400: discriminator loss: 0.6954243183135986, adversarial loss: 0.7441832423210144\n",
      "step 450: discriminator loss: 0.7256754636764526, adversarial loss: 0.7400968074798584\n",
      "step 500: discriminator loss: 0.7020201683044434, adversarial loss: 0.7446410059928894\n",
      "step 550: discriminator loss: 0.6801480054855347, adversarial loss: 0.9143943786621094\n",
      "step 600: discriminator loss: 0.6830952763557434, adversarial loss: 0.7880680561065674\n",
      "step 650: discriminator loss: 0.7454708218574524, adversarial loss: 0.782561182975769\n",
      "step 700: discriminator loss: 0.6792200803756714, adversarial loss: 0.7939407825469971\n",
      "step 750: discriminator loss: 0.6916797757148743, adversarial loss: 0.8157812356948853\n",
      "step 800: discriminator loss: 0.6902390718460083, adversarial loss: 0.750106692314148\n",
      "step 850: discriminator loss: 0.6986071467399597, adversarial loss: 0.7653893232345581\n",
      "step 900: discriminator loss: 0.7069215774536133, adversarial loss: 0.7258030772209167\n",
      "step 950: discriminator loss: 0.6925474405288696, adversarial loss: 0.7341045141220093\n",
      "999/1000: 12.41s - ETA: 12ss\r"
     ]
    }
   ],
   "source": [
    "# GAN çš„è®­ç»ƒã€\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# å¯¼å…¥ CIFAR10 æ•°æ®\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "# é€‰å‡ºé’è›™ğŸ¸çš„å›¾ç‰‡\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) + (height, width, channels)\n",
    ").astype('float32') / 255.\n",
    "\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = 'gan_save'\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # éšæœºé‡‡æ ·æ½œåœ¨ç‚¹\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    # ç”Ÿæˆå›¾åƒ\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    # é€‰å–çœŸå®å›¾åƒ\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    \n",
    "    # åˆå¹¶ç”Ÿæˆã€çœŸå®å›¾åƒï¼Œç»™å‡ºæ ‡ç­¾\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)  # å‘æ ‡ç­¾ä¸­æ·»åŠ éšæœºå™ªå£°\n",
    "    \n",
    "    # è®­ç»ƒåˆ¤åˆ«å™¨\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    # éšæœºé‡‡æ ·æ½œåœ¨ç‚¹\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size, 1))  # è°ç§°å…¨éƒ¨éƒ½æ˜¯çœŸå®å›¾ç‰‡\n",
    "    \n",
    "    # é€šè¿‡ gan æ¨¡å‹è®­ç»ƒç”Ÿæˆå™¨\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "        \n",
    "    if step % 50 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        \n",
    "        print(f'step {step}: discriminator loss: {d_loss}, adversarial loss: {a_loss}')\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'generated_frog_{step}.png'))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'real_frog_{step}.png'))\n",
    "    else:\n",
    "        time_cost = end_time - start_time\n",
    "        time_eta = time_cost * (iterations - step)\n",
    "        print(f'{step}/{iterations}: {time_cost:.2f}s - ETA: {time_eta:.0f}s', end='\\r')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000: discriminator loss: 0.7096449136734009, adversarial loss: 0.752526581287384\n"
     ]
    }
   ],
   "source": [
    "for step in range(iterations, iterations+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # éšæœºé‡‡æ ·æ½œåœ¨ç‚¹\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    # ç”Ÿæˆå›¾åƒ\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    # é€‰å–çœŸå®å›¾åƒ\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    \n",
    "    # åˆå¹¶ç”Ÿæˆã€çœŸå®å›¾åƒï¼Œç»™å‡ºæ ‡ç­¾\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)  # å‘æ ‡ç­¾ä¸­æ·»åŠ éšæœºå™ªå£°\n",
    "    \n",
    "    # è®­ç»ƒåˆ¤åˆ«å™¨\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    # éšæœºé‡‡æ ·æ½œåœ¨ç‚¹\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size, 1))  # è°ç§°å…¨éƒ¨éƒ½æ˜¯çœŸå®å›¾ç‰‡\n",
    "    \n",
    "    # é€šè¿‡ gan æ¨¡å‹è®­ç»ƒç”Ÿæˆå™¨\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "        \n",
    "    if step % 50 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        \n",
    "        print(f'step {step}: discriminator loss: {d_loss}, adversarial loss: {a_loss}')\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'generated_frog_{step}.png'))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'real_frog_{step}.png'))\n",
    "    else:\n",
    "        time_cost = end_time - start_time\n",
    "        time_eta = time_cost * (iterations - step)\n",
    "        print(f'{step}/{iterations}: {time_cost:.2f}s - ETA: {time_eta:.0f}s', end='\\r')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€åè¾“å‡ºçš„å›¾åƒï¼š\n",
    "\n",
    "![æœ€åè¾“å‡ºçš„å›¾åƒ](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi27n2ulptj300w00w0si.jpg)\n",
    "\n",
    "æ•ˆæœç›¸å½“å·®ã€‚è¿™ä¸ªä¸œè¥¿è®­ç»ƒæ¶ˆè€—å¤ªå¤§äº†ï¼Œåˆæ˜¯ CPU åŠé€€ï¼Œæˆ‘åªè·‘äº† 1000 è½®ï¼Œè¿˜å¤ªå°‘äº†ã€‚ã€‚ã€‚ä¸æ„§ä¸ºå…¨ä¹¦æœ€åä¸€é¢˜ï¼Œå‹è½´ï¼Œè¿™å°é’è›™å›¾æˆ‘ä¸è¦äº†ã€‚ğŸ˜‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
